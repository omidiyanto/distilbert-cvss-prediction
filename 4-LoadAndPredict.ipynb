{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Semua model berhasil dimuat:\n",
      "['attack_vector', 'attack_complexity', 'privileges_required', 'user_interaction', 'scope', 'integrity_impact', 'confidentiality_impact', 'availability_impact']\n"
     ]
    }
   ],
   "source": [
    "from transformers import DistilBertForSequenceClassification, DistilBertTokenizer\n",
    "import torch\n",
    "\n",
    "# Folder model dan nama kategori\n",
    "model_folders = {\n",
    "    \"attack_vector\": \"output/attackVector\",\n",
    "    \"attack_complexity\": \"output/attackComplexity\",\n",
    "    \"privileges_required\": \"output/privilegeReq\",\n",
    "    \"user_interaction\": \"output/userinteraction\",\n",
    "    \"scope\": \"output/scope\",\n",
    "    \"integrity_impact\": \"output/integrity\",\n",
    "    \"confidentiality_impact\": \"output/confidentiality\",\n",
    "    \"availability_impact\": \"output/availability\",\n",
    "}\n",
    "\n",
    "# Memuat tokenizer (gunakan satu tokenizer karena semua model berbasis DistilBERT)\n",
    "tokenizer = DistilBertTokenizer.from_pretrained(\"distilbert-base-uncased\")\n",
    "\n",
    "# Memuat model\n",
    "models = {}\n",
    "for category, folder in model_folders.items():\n",
    "    model = DistilBertForSequenceClassification.from_pretrained(folder)\n",
    "    models[category] = model\n",
    "\n",
    "# Menampilkan hasil pemuatan\n",
    "print(\"Semua model berhasil dimuat:\")\n",
    "print(list(models.keys()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hasil prediksi:\n",
      "attack_vector: 2\n",
      "attack_complexity: 0\n",
      "privileges_required: 0\n",
      "user_interaction: 0\n",
      "scope: 0\n",
      "integrity_impact: 2\n",
      "confidentiality_impact: 0\n",
      "availability_impact: 0\n"
     ]
    }
   ],
   "source": [
    "# Input teks\n",
    "input_text = \"Improper conditions check in some Intel(R) Ethernet Controllers 800 series Linux drivers before version 1.4.11 may allow an authenticated user to potentially enable information disclosure or denial of service via local access.\"\n",
    "\n",
    "# Tokenisasi input\n",
    "inputs = tokenizer(input_text, return_tensors=\"pt\", padding=True, truncation=True, max_length=512)\n",
    "\n",
    "# Prediksi dengan semua model\n",
    "outputs = {}\n",
    "for category, model in models.items():\n",
    "    with torch.no_grad():\n",
    "        logits = model(**inputs).logits\n",
    "        prediction = torch.argmax(logits, dim=-1).item()\n",
    "        outputs[category] = prediction\n",
    "\n",
    "# Menampilkan hasil prediksi\n",
    "print(\"Hasil prediksi:\")\n",
    "for category, prediction in outputs.items():\n",
    "    print(f\"{category}: {prediction}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device: cpu\n",
      "Predicted class: 0\n",
      "Predicted probabilities: tensor([[0.9554, 0.0376, 0.0070]])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
    "from torch.utils.data import DataLoader\n",
    "import numpy as np\n",
    "from sklearn.metrics import f1_score, precision_score, recall_score, accuracy_score, balanced_accuracy_score\n",
    "\n",
    "# -------------------------------------- MODEL -------------------------------------\n",
    "\n",
    "def load_model(model_path):\n",
    "    \"\"\"\n",
    "    Load the pre-trained model from the specified path.\n",
    "    \"\"\"\n",
    "    model = AutoModelForSequenceClassification.from_pretrained(model_path)\n",
    "    return model\n",
    "\n",
    "def load_tokenizer(model_name, extra_tokens, token_file, model_path, config_path):\n",
    "    \"\"\"\n",
    "    Load the tokenizer and model based on the model name and additional configurations.\n",
    "    \"\"\"\n",
    "    if model_name == 'distilbert':\n",
    "        from transformers import DistilBertTokenizerFast\n",
    "        tokenizer = DistilBertTokenizerFast.from_pretrained('distilbert-base-cased')\n",
    "    elif model_name == 'bert':\n",
    "        from transformers import BertTokenizerFast\n",
    "        tokenizer = BertTokenizerFast.from_pretrained('bert-base-uncased')\n",
    "    elif model_name == 'deberta':\n",
    "        from transformers import DebertaTokenizerFast\n",
    "        tokenizer = DebertaTokenizerFast.from_pretrained('microsoft/deberta-base')\n",
    "    elif model_name == 'roberta':\n",
    "        from transformers import RobertaTokenizerFast\n",
    "        tokenizer = RobertaTokenizerFast.from_pretrained('roberta-base')\n",
    "    else:\n",
    "        raise ValueError(f\"Unknown model type {model_name}\")\n",
    "\n",
    "    # Add custom tokens if provided\n",
    "    if extra_tokens:\n",
    "        add_tokens_from_file(token_file, tokenizer)\n",
    "    \n",
    "    return tokenizer\n",
    "\n",
    "def add_tokens_from_file(token_file, tokenizer):\n",
    "    \"\"\"\n",
    "    Add tokens from a file to the tokenizer.\n",
    "    \"\"\"\n",
    "    with open(token_file, 'r') as file:\n",
    "        token_list = [line.strip() for line in file]\n",
    "    tokenizer.add_tokens(token_list)\n",
    "\n",
    "# -------------------------------------- PREDICTION --------------------------------\n",
    "\n",
    "def predict(input_description, model, tokenizer, device):\n",
    "    \"\"\"\n",
    "    Make a prediction for a single input description using the trained model and tokenizer.\n",
    "    \"\"\"\n",
    "    # Tokenize the input text\n",
    "    inputs = tokenizer(input_description, return_tensors='pt', truncation=True, padding=True, max_length=512).to(device)\n",
    "\n",
    "    # Get predictions from the model\n",
    "    with torch.no_grad():\n",
    "        outputs = model(**inputs)\n",
    "        logits = outputs.logits\n",
    "        softmax = torch.nn.Softmax(dim=1)\n",
    "        probs = softmax(logits)\n",
    "    \n",
    "    predicted_class = torch.argmax(probs, dim=1).item()\n",
    "    return predicted_class, probs\n",
    "\n",
    "# -------------------------------------- MAIN -----------------------------------\n",
    "\n",
    "def main():\n",
    "    # Set the device (GPU or CPU)\n",
    "    device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
    "    print(\"Device:\", device)\n",
    "\n",
    "    # Paths and configurations\n",
    "    model_path = \"output/privilegeReq//\"\n",
    "    config_path = \"output/config.json\"\n",
    "    tokenizer_model_name = 'distilbert'  # Change to your model type (e.g., bert, roberta, etc.)\n",
    "    extra_tokens = False  # Set to True if you want to load extra tokens\n",
    "    token_file = \"vocab/CVSS_5k.vocab\"\n",
    "\n",
    "    # Load model and tokenizer\n",
    "    model = load_model(model_path).to(device)\n",
    "    tokenizer = load_tokenizer(tokenizer_model_name, extra_tokens, token_file, model_path, config_path)\n",
    "\n",
    "    # Example input description\n",
    "    input_description = \"A vulnerability in Cisco Intercloud Fabric for Business and Cisco Intercloud Fabric for Providers could allow an unauthenticated, remote attacker to connect to the database used by these products. More Information: CSCus99394. Known Affected Releases: 7.3(0)ZN(0.99).\"\n",
    "\n",
    "    # Get the predicted class and probabilities\n",
    "    predicted_class, probs = predict(input_description, model, tokenizer, device)\n",
    "    \n",
    "    print(f\"Predicted class: {predicted_class}\")\n",
    "    print(f\"Predicted probabilities: {probs}\")\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
